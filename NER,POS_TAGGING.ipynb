{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER,POS TAGGING.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavansai26/pos-tagging-NER-in-nlp/blob/master/NER%2CPOS_TAGGING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEsE68IE9fBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import wordnet\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8FBHv8O9olI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "syns = wordnet.synsets(\"program\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdS1oeXp9tni",
        "colab_type": "code",
        "outputId": "de1cf859-9e8b-4d1f-aa92-56b725452524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(syns[0].lemmas()[0].name())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "plan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zi52Z5I99TC",
        "colab_type": "code",
        "outputId": "91c6f1d7-8108-4bd5-e918-a6b79a1c1608",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(syns[0].definition())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a series of steps to be carried out or goals to be accomplished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1wRrSKU-A-b",
        "colab_type": "code",
        "outputId": "a676db89-9768-452b-9519-43f1d3d6ae8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(syns[0].examples())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['they drew up a six-step plan', 'they discussed plans for a new bond issue']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJShsx-sBRIN",
        "colab_type": "code",
        "outputId": "09eec278-9966-468c-ffb7-84561596e8c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "nltk.download('words')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pxUbbnA-Fe5",
        "colab_type": "code",
        "outputId": "dd6be54b-11c3-4fbb-f12c-50fdbdcd4fc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "synonyms = []\n",
        "antonyms = []\n",
        "\n",
        "for syn in wordnet.synsets(\"good\"):\n",
        "    for l in syn.lemmas():\n",
        "        synonyms.append(l.name())\n",
        "        if l.antonyms():\n",
        "            antonyms.append(l.antonyms()[0].name())\n",
        "\n",
        "print(set(synonyms))\n",
        "print(set(antonyms))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'effective', 'just', 'right', 'expert', 'estimable', 'in_force', 'thoroughly', 'in_effect', 'undecomposed', 'respectable', 'secure', 'trade_good', 'well', 'beneficial', 'dependable', 'unspoilt', 'upright', 'salutary', 'full', 'commodity', 'sound', 'safe', 'honest', 'soundly', 'skillful', 'ripe', 'near', 'proficient', 'skilful', 'honorable', 'adept', 'serious', 'good', 'practiced', 'goodness', 'dear', 'unspoiled'}\n",
            "{'badness', 'bad', 'evilness', 'evil', 'ill'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anTP7Z-T-Kjk",
        "colab_type": "code",
        "outputId": "509cc7a3-3a31-4a88-a6f8-8496b6758331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "w1 = wordnet.synset('ship.n.01')\n",
        "w2 = wordnet.synset('boat.n.01')\n",
        "print(w1.wup_similarity(w2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9090909090909091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am8285Lu-P_V",
        "colab_type": "code",
        "outputId": "2ca1ad4c-9152-448b-d13d-a1458e4bc82d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "w1 = wordnet.synset('ship.n.01')\n",
        "w2 = wordnet.synset('car.n.01')\n",
        "print(w1.wup_similarity(w2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6956521739130435\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHQBFO-3-UNh",
        "colab_type": "code",
        "outputId": "b7d72b50-0272-440a-c985-91735389e7d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "w1 = wordnet.synset('ship.n.01')\n",
        "w2 = wordnet.synset('cat.n.01')\n",
        "print(w1.wup_similarity(w2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU3yNiUm-X_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tag import StanfordNERTagger\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNMsuj3Z_SLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import time\n",
        "\n",
        "exampleArray = ['The incredibly intimidating NLP scares people away who are sissies.']\n",
        "\n",
        "\n",
        "contentArray =['Starbucks is not doing very well lately.',\n",
        "               'Overall, while it may seem there is already a Starbucks on every corner, Starbucks still has a lot of room to grow.',\n",
        "               'They just began expansion into food products, which has been going quite well so far for them.',\n",
        "               'I can attest that my own expenditure when going to Starbucks has increased, in lieu of these food products.',\n",
        "               'Starbucks is also indeed expanding their number of stores as well.',\n",
        "               'Starbucks still sees strong sales growth here in the united states, and intends to actually continue increasing this.',\n",
        "               'Starbucks also has one of the more successful loyalty programs, which accounts for 30%  of all transactions being loyalty-program-based.',\n",
        "               'As if news could not get any more positive for the company, Brazilian weather has become ideal for producing coffee beans.',\n",
        "               'Brazil is the world\\'s #1 coffee producer, the source of about 1/3rd of the entire world\\'s supply!',\n",
        "               'Given the dry weather, coffee farmers have amped up production, to take as much of an advantage as possible with the dry weather.',\n",
        "               'Increase in supply... well you know the rules...',]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA6WwgFmAh3w",
        "colab_type": "code",
        "outputId": "040bd3d6-3e91-46d4-ebb9-5f985e12ecdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "def processLanguage():\n",
        "    try:\n",
        "        for item in contentArray:\n",
        "            tokenized = nltk.word_tokenize(item)\n",
        "            tagged = nltk.pos_tag(tokenized)\n",
        "            print (tagged)\n",
        "\n",
        "            namedEnt = nltk.ne_chunk(tagged)\n",
        "            namedEnt.draw()\n",
        "\n",
        "            time.sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        print (str(e))\n",
        "        \n",
        "\n",
        "processLanguage()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Starbucks', 'NNS'), ('is', 'VBZ'), ('not', 'RB'), ('doing', 'VBG'), ('very', 'RB'), ('well', 'RB'), ('lately', 'RB'), ('.', '.')]\n",
            "no display name and no $DISPLAY environment variable\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F48l0cr8Ambt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIoqJIwuCCti",
        "colab_type": "text"
      },
      "source": [
        "CC coordinating conjunction\n",
        "CD cardinal digit\n",
        "DT determiner\n",
        "EX existential there (like: “there is” … think of it like “there exists”)\n",
        "FW foreign word\n",
        "IN preposition/subordinating conjunction\n",
        "JJ adjective ‘big’\n",
        "JJR adjective, comparative ‘bigger’\n",
        "JJS adjective, superlative ‘biggest’\n",
        "LS list marker 1)\n",
        "MD modal could, will\n",
        "NN noun, singular ‘desk’\n",
        "NNS noun plural ‘desks’\n",
        "NNP proper noun, singular ‘Harrison’\n",
        "NNPS proper noun, plural ‘Americans’\n",
        "PDT predeterminer ‘all the kids’\n",
        "POS possessive ending parent’s\n",
        "PRP personal pronoun I, he, she\n",
        "PRP$ possessive pronoun my, his, hers\n",
        "RB adverb very, silently,\n",
        "RBR adverb, comparative better\n",
        "RBS adverb, superlative best\n",
        "RP particle give up\n",
        "TO, to go ‘to’ the store.\n",
        "UH interjection\n",
        "VB verb, base form take\n",
        "VBD verb, past tense took\n",
        "VBG verb, gerund/present participle taking\n",
        "VBN verb, past participle taken\n",
        "VBP verb, sing. present, non-3d take\n",
        "VBZ verb, 3rd person sing. present takes\n",
        "WDT wh-determiner which\n",
        "WP wh-pronoun who, what\n",
        "WP$ possessive wh-pronoun whose\n",
        "WRB wh-abverb where, wh\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4Jj0B9aCFE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxX43Q8eD-T9",
        "colab_type": "text"
      },
      "source": [
        "The Different POS Tagging Techniques\n",
        "There are different techniques for POS Tagging:\n",
        "Lexical Based Methods — Assigns the POS tag the most frequently occurring with a word in the training corpus.\n",
        "\n",
        "\n",
        "\n",
        "Rule-Based Methods — Assigns POS tags based on rules. For example, we can have a rule that says, words ending with “ed” or “ing” must be assigned to a verb. Rule-Based Techniques can be used along with Lexical Based approaches to allow POS Tagging of words that are not present in the training corpus but are there in the testing data.\n",
        "Probabilistic Methods — This method assigns the POS tags based on the probability of a particular tag sequence occurring. Conditional Random Fields (CRFs) and Hidden Markov Models (HMMs) are probabilistic approaches to assign a POS Tag.\n",
        "Deep Learning Methods — Recurrent Neural Networks can also be used for POS tagging.\n",
        "In this article, we will look at using Conditional Random Fields on the Penn Treebank Corpus (this is present in the NLTK library).\n",
        "Conditional Random Fields(CRF)\n",
        "\n",
        "In CRFs, the input is a set of features (real numbers) derived from the input sequence using feature functions, the weights associated with the features (that are learned) and the previous label and the task is to predict the current label. The weights of different feature functions will be determined such that the likelihood of the labels in the training data will be maximised.\n",
        "In CRF, a set of feature functions are defined to extract features for each word in a sentence. Some examples of feature functions are: is the first letter of the word capitalised, what the suffix and prefix of the word, what is the previous word, is it the first or the last word of the sentence, is it a number etc. These set of features are called State Features. In CRF, we also pass the label of the previous word and the label of the current word to learn the weights. CRF will try to determine the weights of different feature functions that will maximise the likelihood of the labels in the training data. The feature function dependent on the label of the previous word is Transition Feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhRri5ULENYL",
        "colab_type": "text"
      },
      "source": [
        "A CRF is a Discriminative Probabilistic Classifiers. The difference between discriminative and generative models is that while discriminative models try to model conditional probability distribution, i.e., P(y|x), generative models try to model a joint probability distribution, i.e., P(x,y).\n",
        "Logistic Regression, SVM, CRF are Discriminative Classifiers. Naive Bayes, HMMs are Generative Classifiers. CRF’s can also be used for sequence labelling tasks like Named Entity Recognisers and POS Taggers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkhSDpbTEae0",
        "colab_type": "text"
      },
      "source": [
        "In CRFs, the input is a set of features (real numbers) derived from the input sequence using feature functions, the weights associated with the features (that are learned) and the previous label and the task is to predict the current label. The weights of different feature functions will be determined such that the likelihood of the labels in the training data will be maximised. In CRF, a set of feature functions are defined to extract features for each word in a sentence. Some examples of feature functions are: is the first letter of the word capitalised, what the suffix and prefix of the word, what is the previous word, is it the first or the last word of the sentence, is it a number etc. These set of features are called State Features. In CRF, we also pass the label of the previous word and the label of the current word to learn the weights. CRF will try to determine the weights of different feature functions that will maximise the likelihood of the labels in the training data. The feature function dependent on the label of the previous word is Transition Feature"
      ]
    }
  ]
}